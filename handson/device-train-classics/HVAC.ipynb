{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c017ee-af86-475a-a92b-508f1271fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b0dd6-af1a-4e58-b862-57aa8a08c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ae8c7-31a1-4e53-80f4-3e5103ed255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def farenheight_to_celcius(values):\n",
    "    return (values - 32) * 5/9.0 \n",
    "    \n",
    "def load_data(path, resample=None):\n",
    "\n",
    "    df = pandas.read_csv(path)\n",
    "\n",
    "    df.columns = [c.strip().removeprefix('AHU: ').removesuffix('Signal').strip() for c in df.columns]\n",
    "    df['Time'] = pandas.to_datetime(df['Datetime'])\n",
    "    df = df.drop(columns=['Datetime'])\n",
    "\n",
    "    df = df.rename(columns={'Occupancy Mode Indicator': 'Occupied', 'Fault Detection Ground Truth': 'Fault'})\n",
    "    df = df.set_index('Time')\n",
    "    #df['Fault'] = df.Fault.astype(float)\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].replace({'#VALUE!': None}).astype(numpy.float32)\n",
    "        if 'Temperature' in c:\n",
    "            df[c] = farenheight_to_celcius(df[c])\n",
    "\n",
    "    if resample is not None:\n",
    "        df = df.resample(resample).agg('median')\n",
    "        \n",
    "    return df\n",
    "\n",
    "path = 'data/SZVAV.csv'\n",
    "df = load_data(path, resample='10min')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f89d5-13df-4c6e-ae75-4ef26d6411b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_grouped_timeseries(df, date_col, groups, title=\"Grouped Time Series\", \n",
    "                          height=None, colors=None, show_legend=True):\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    if height is None:\n",
    "        height = 200 * len(groups) + 100\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=len(groups),\n",
    "        cols=1,\n",
    "        subplot_titles=list(groups.keys()),\n",
    "        vertical_spacing=0.08,\n",
    "        shared_xaxes=True\n",
    "    )\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if colors is None:\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                 '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    \n",
    "    color_idx = 0\n",
    "\n",
    "    df = df.sort_values(date_col)\n",
    "    \n",
    "    # Plot each group in its own subplot\n",
    "    for i, (group_name, columns) in enumerate(groups.items(), 1):\n",
    "        for col in columns:\n",
    "            #print(df[col])\n",
    "            #print()\n",
    "            y_data = [ float(d) for d in df[col].copy() ] # XXX: no idea why have to convert to floats\n",
    "            times = df[date_col].values\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=times,\n",
    "                    y=y_data,\n",
    "                    mode='lines',\n",
    "                    #mode='markers',\n",
    "                    marker=dict(size=3.0),\n",
    "                    name=col,\n",
    "                    #legendgroup=group_name,\n",
    "                    showlegend=show_legend,\n",
    "                    line=dict(color=colors[color_idx % len(colors)]),\n",
    "                    #connectgaps=False,\n",
    "                ),\n",
    "                row=i, col=1\n",
    "            )\n",
    "            color_idx += 1\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        height=height,\n",
    "        hovermode='x unified',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        ) if show_legend else None\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text=\"Date\", row=len(groups), col=1)\n",
    "    \n",
    "    for i, group_name in enumerate(groups.keys(), 1):\n",
    "        fig.update_yaxes(title_text=f\"{group_name}\", row=i, col=1)\n",
    "        pass\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "indicators = [\n",
    "    'Fault',\n",
    "    'Occupied',\n",
    "]\n",
    "control = [\n",
    "    'Cooling Coil Valve Control',\n",
    "    'Exhaust Air Damper Control',\n",
    "    'Heating Coil Valve Control',\n",
    "    'Outdoor Air Damper Control',\n",
    "    'Return Air Damper Control',\n",
    "    'Supply Air Fan Speed Control',\n",
    "    'Supply Air Fan Status',\n",
    "]\n",
    "temperatures = [\n",
    "    'Outdoor Air Temperature',\n",
    "    'Return Air Temperature',\n",
    "    'Mixed Air Temperature',\n",
    "    'Supply Air Temperature',\n",
    "    'Supply Air Temperature Cooling Set Point',\n",
    "    'Supply Air Temperature Heating Set Point',\n",
    "]\n",
    "\n",
    "# Define groups\n",
    "groups = {\n",
    "    'Ind': indicators,\n",
    "    'Control': control,\n",
    "    'Temperatures': temperatures,\n",
    "}\n",
    "\n",
    "# Create the plot\n",
    "fig = plot_grouped_timeseries(\n",
    "    df=df.reset_index(),\n",
    "    date_col='Time',\n",
    "    groups=groups,\n",
    "    title='foo',\n",
    "    height=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5a289-a734-4475-97e2-691e9848f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hvac_arimax import ARIMAXAnomalyDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229377d2-7cb3-4053-93c4-67d9d4fe18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def anomaly_detection(data, target, covariates=[]):\n",
    "    \n",
    "    assert isinstance(data.index, pandas.DatetimeIndex), type(data.index)\n",
    "    assert df.index.is_monotonic_increasing\n",
    "    \n",
    "    # Prepare data\n",
    "    y = data[target]\n",
    "    X = data[covariates]\n",
    "    timestamps = data.index\n",
    "\n",
    "    # Split into train/test\n",
    "    train_size = int(0.8 * len(data))\n",
    "    y_train = y[:train_size]\n",
    "    X_train = X[:train_size]\n",
    "    timestamps_train = timestamps[:train_size]\n",
    "    \n",
    "    y_test = y[train_size:]\n",
    "    X_test = X[train_size:]\n",
    "    timestamps_test = timestamps[train_size:]\n",
    "\n",
    "    seasonal_period = int(pandas.Timedelta(hours=24 ) / df.index.freq)\n",
    "    \n",
    "    arimax_detector = ARIMAXAnomalyDetector(\n",
    "        ar_order=2,\n",
    "        ma_order=1,\n",
    "        diff_order=1,\n",
    "        seasonal_ar=0,\n",
    "        seasonal_ma=0,\n",
    "        seasonal_period=seasonal_period,\n",
    "        anomaly_threshold=3.0\n",
    "    )\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    \n",
    "    arimax_detector.fit(y_train, X_train, timestamps_train)\n",
    "    \n",
    "    # Detect anomalies on test data\n",
    "    print(\"Detecting anomalies...\")\n",
    "    anomaly_scores, anomalies, predictions = arimax_detector.detect_anomalies(\n",
    "        y_test, X_test, timestamps_test\n",
    "    )\n",
    "    \n",
    "    # Print feature importance (coefficients)\n",
    "    print(\"\\nModel coefficients:\")\n",
    "    for i, coef in enumerate(arimax_detector.model.coef_):\n",
    "        if i < len(arimax_detector.feature_names_):\n",
    "            print(f\"{arimax_detector.feature_names_[i]}: {coef:.4f}\")\n",
    "    \n",
    "    # Calculate performance metrics on aligned data\n",
    "    valid_mask = ~(y_test.isna() | predictions.isna())\n",
    "    y_test_aligned = y_test[valid_mask]\n",
    "    predictions_aligned = predictions[valid_mask]\n",
    "\n",
    "    np = numpy\n",
    "    def smape(y_true, y_pred):\n",
    "       \"\"\"Symmetric Mean Absolute Percentage Error\"\"\"\n",
    "       return 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "    # Usage with the ARIMAX model\n",
    "    valid_mask = ~(y_test.isna() | predictions.isna())\n",
    "    smape_score = smape(y_test[valid_mask], predictions[valid_mask])\n",
    "    print(f\"SMAPE: {smape_score:.2f}%\")\n",
    "    \n",
    "    if len(y_test_aligned) > 0:\n",
    "        test_mse = mean_squared_error(y_test_aligned, predictions_aligned)\n",
    "        test_mae = mean_absolute_error(y_test_aligned, predictions_aligned)\n",
    "        print(f\"\\nTest MSE: {test_mse:.4f}\")\n",
    "        print(f\"Test MAE: {test_mae:.4f}\")\n",
    "        print(f\"Evaluated on {len(y_test_aligned)} valid points\")\n",
    "    else:\n",
    "        print(\"\\nNo valid predictions to evaluate\")\n",
    "    \n",
    "    # Plot results\n",
    "    arimax_detector.plot_results(y_test, anomaly_scores, anomalies, predictions)\n",
    "\n",
    "covariates = [\n",
    "    'Occupied',\n",
    "    'Outdoor Air Temperature',\n",
    "]\n",
    "anomaly_detection(df, target='Supply Air Temperature', covariates=covariates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816a96a5-5cd0-4210-be7b-978c0bfcae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import ARIMA\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da48a1ef-2df9-4487-9786-679a22be2510",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Convert to Darts TimeSeries\n",
    "ts = TimeSeries.from_dataframe(df, time_col='timestamp', value_cols=['target'])\n",
    "exog = TimeSeries.from_dataframe(df, time_col='timestamp', value_cols=['outdoor_temp', 'occupancy'])\n",
    "\n",
    "# Fit ARIMAX\n",
    "model = ARIMA(p=1, d=1, q=0)\n",
    "model.fit(ts, future_covariates=exog)\n",
    "\n",
    "# Predict\n",
    "forecast = model.predict(n=100, future_covariates=exog_future)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
