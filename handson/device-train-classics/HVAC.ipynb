{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c017ee-af86-475a-a92b-508f1271fef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797b0dd6-af1a-4e58-b862-57aa8a08c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas\n",
    "import numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579ae8c7-31a1-4e53-80f4-3e5103ed255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def farenheight_to_celcius(values):\n",
    "    return (values - 32) * 5/9.0 \n",
    "    \n",
    "def load_data(path, resample=None):\n",
    "\n",
    "    df = pandas.read_csv(path)\n",
    "\n",
    "    df.columns = [c.strip().removeprefix('AHU: ').removesuffix('Signal').strip() for c in df.columns]\n",
    "    df['Time'] = pandas.to_datetime(df['Datetime'])\n",
    "    df = df.drop(columns=['Datetime'])\n",
    "\n",
    "    df = df.rename(columns={'Occupancy Mode Indicator': 'Occupied', 'Fault Detection Ground Truth': 'Fault'})\n",
    "    df = df.set_index('Time')\n",
    "    #df['Fault'] = df.Fault.astype(float)\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].replace({'#VALUE!': None}).astype(numpy.float32)\n",
    "        if 'Temperature' in c:\n",
    "            df[c] = farenheight_to_celcius(df[c])\n",
    "\n",
    "    if resample is not None:\n",
    "        df = df.resample(resample).agg('median')\n",
    "        \n",
    "    return df\n",
    "\n",
    "path = 'data/SZVAV.csv'\n",
    "df = load_data(path, resample='10min')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f89d5-13df-4c6e-ae75-4ef26d6411b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_grouped_timeseries(df, date_col, groups, title=\"Grouped Time Series\", \n",
    "                          height=None, colors=None, show_legend=True):\n",
    "\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "\n",
    "    if height is None:\n",
    "        height = 200 * len(groups) + 100\n",
    "    \n",
    "    # Create subplots\n",
    "    fig = make_subplots(\n",
    "        rows=len(groups),\n",
    "        cols=1,\n",
    "        subplot_titles=list(groups.keys()),\n",
    "        vertical_spacing=0.08,\n",
    "        shared_xaxes=True\n",
    "    )\n",
    "    \n",
    "    # Default colors if not provided\n",
    "    if colors is None:\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "                 '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf']\n",
    "    \n",
    "    color_idx = 0\n",
    "\n",
    "    df = df.sort_values(date_col)\n",
    "    \n",
    "    # Plot each group in its own subplot\n",
    "    for i, (group_name, columns) in enumerate(groups.items(), 1):\n",
    "        for col in columns:\n",
    "            #print(df[col])\n",
    "            #print()\n",
    "            y_data = [ float(d) for d in df[col].copy() ] # XXX: no idea why have to convert to floats\n",
    "            times = df[date_col].values\n",
    "            fig.add_trace(\n",
    "                go.Scatter(\n",
    "                    x=times,\n",
    "                    y=y_data,\n",
    "                    mode='lines',\n",
    "                    #mode='markers',\n",
    "                    marker=dict(size=3.0),\n",
    "                    name=col,\n",
    "                    #legendgroup=group_name,\n",
    "                    showlegend=show_legend,\n",
    "                    line=dict(color=colors[color_idx % len(colors)]),\n",
    "                    #connectgaps=False,\n",
    "                ),\n",
    "                row=i, col=1\n",
    "            )\n",
    "            color_idx += 1\n",
    "    \n",
    "    # Update layout\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        height=height,\n",
    "        hovermode='x unified',\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"top\",\n",
    "            y=1,\n",
    "            xanchor=\"left\",\n",
    "            x=1.02\n",
    "        ) if show_legend else None\n",
    "    )\n",
    "    \n",
    "    # Update axes\n",
    "    fig.update_xaxes(title_text=\"Date\", row=len(groups), col=1)\n",
    "    \n",
    "    for i, group_name in enumerate(groups.keys(), 1):\n",
    "        fig.update_yaxes(title_text=f\"{group_name}\", row=i, col=1)\n",
    "        pass\n",
    "\n",
    "\n",
    "    # Move legend to bottom center\n",
    "    fig.update_layout(\n",
    "        legend=dict(\n",
    "            orientation='h',      # horizontal layout\n",
    "            yanchor='bottom',\n",
    "            y=-0.2,               # adjust this to move further down\n",
    "            xanchor='center',\n",
    "            x=0.5\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "indicators = [\n",
    "    'Fault',\n",
    "    'Occupied',\n",
    "]\n",
    "control = [\n",
    "    'Cooling Coil Valve Control',\n",
    "    'Exhaust Air Damper Control',\n",
    "    'Heating Coil Valve Control',\n",
    "    'Outdoor Air Damper Control',\n",
    "    'Return Air Damper Control',\n",
    "    'Supply Air Fan Speed Control',\n",
    "    'Supply Air Fan Status',\n",
    "]\n",
    "temperatures = [\n",
    "    'Outdoor Air Temperature',\n",
    "    'Return Air Temperature',\n",
    "    'Mixed Air Temperature',\n",
    "    'Supply Air Temperature',\n",
    "    'Supply Air Temperature Cooling Set Point',\n",
    "    'Supply Air Temperature Heating Set Point',\n",
    "]\n",
    "\n",
    "# Define groups\n",
    "groups = {\n",
    "    'Ind': indicators,\n",
    "    'Control': control,\n",
    "    'Temperatures': temperatures,\n",
    "}\n",
    "\n",
    "# Create the plot\n",
    "fig = plot_grouped_timeseries(\n",
    "    df=df.reset_index(),\n",
    "    date_col='Time',\n",
    "    groups=groups,\n",
    "    title='foo',\n",
    "    height=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd5a289-a734-4475-97e2-691e9848f43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from arimax import ARIMAXAnomalyDetector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229377d2-7cb3-4053-93c4-67d9d4fe18fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "def anomaly_detect_period(model,\n",
    "                          X_train, y_train, timestamps_train,\n",
    "                          X_test, y_test, timestamps_test):\n",
    "    \n",
    "    model.fit(y_train, X_train, timestamps_train)\n",
    "    \n",
    "    # Detect anomalies on test data\n",
    "    anomaly_scores, anomalies, predictions = model.detect_anomalies(\n",
    "        y_test, X_test, timestamps_test\n",
    "    )\n",
    "\n",
    "    # Calculate performance metrics on aligned data\n",
    "    valid_mask = ~(y_test.isna() | predictions.isna())\n",
    "    y_test_aligned = y_test[valid_mask]\n",
    "    predictions_aligned = predictions[valid_mask]\n",
    "    timestamps_aligned = timestamps_test[valid_mask]\n",
    "\n",
    "    pred = pandas.DataFrame({\n",
    "        'time': timestamps_aligned,\n",
    "        'prediction': predictions_aligned,\n",
    "        'input': y_test_aligned,\n",
    "    })\n",
    "    # TODO: also include train data, for diagnostics\n",
    "    return pred\n",
    "    \n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"Symmetric Mean Absolute Percentage Error\"\"\"\n",
    "    np = numpy\n",
    "    return 100 * np.mean(2 * np.abs(y_true - y_pred) / (np.abs(y_true) + np.abs(y_pred)))\n",
    "\n",
    "def anomaly_detection(data, target, make_detector, covariates=[],\n",
    "                      lookback='5d', predict='4h', hop='1h'):\n",
    "    \n",
    "    assert isinstance(data.index, pandas.DatetimeIndex), type(data.index)\n",
    "    assert df.index.is_monotonic_increasing\n",
    "\n",
    "    hop = pandas.Timedelta(hop)\n",
    "    predict = pandas.Timedelta(predict)\n",
    "    lookback = pandas.Timedelta(lookback)\n",
    "    \n",
    "    # Determine periods\n",
    "    data_start = data.index.min()\n",
    "    data_end = data.index.max()\n",
    "    output_start = data_start + lookback\n",
    "    output_end = data_end\n",
    "\n",
    "    periods = pandas.date_range(output_start, output_end, freq=hop)\n",
    "    #print(periods)\n",
    "    print(data_start, data_end, hop, len(periods))\n",
    "    \n",
    "    # For each period, do forecasting and anomaly scoring\n",
    "    outputs = []\n",
    "    models = []\n",
    "    for predict_start in periods:\n",
    "        predict_end = predict_start + predict\n",
    "        train_start = predict_start - lookback\n",
    "        train_end = predict_start\n",
    "        assert train_start >= data_start\n",
    "\n",
    "        train_data = data.loc[train_start:train_end]\n",
    "        test_data = data.loc[predict_start:predict_end]\n",
    "\n",
    "        model = make_detector()\n",
    "        pred = anomaly_detect_period(model,\n",
    "                              train_data[covariates], train_data[target], train_data.index,\n",
    "                              test_data[covariates], test_data[target], test_data.index,\n",
    "        ) \n",
    "        pred['period'] = predict_start\n",
    "        models.append(model)\n",
    "        outputs.append(pred)\n",
    "\n",
    "    out = pandas.concat(outputs)\n",
    "    \n",
    "    def score_period(df):\n",
    "        s = smape(y_true, y_pred)\n",
    "        pass\n",
    "        \n",
    "    # TODO: aggregate and compute anomaly scores\n",
    "    aggregated = out.groupby('time').agg('median', numeric_only=True)\n",
    "\n",
    "    coefficients = pandas.DataFrame([ dict(zip(m.feature_names_, m.model.coef_)) for m in models ])\n",
    "    coefficients['time'] = periods\n",
    "    coefficients = coefficients.set_index('time')\n",
    "    \n",
    "    return aggregated, coefficients\n",
    "\n",
    "\n",
    "def make_detector():\n",
    "    seasonal_period = int(pandas.Timedelta(hours=1*24 ) / df.index.freq)\n",
    "\n",
    "    import elastic_net_linear as enl\n",
    "    regression = enl.ElasticNetRegression(alpha=0.01, l1_ratio=0.5, max_iterations=1000, verbose=False)\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "    #regression = LinearRegression()\n",
    "    #regression = ElasticNet(alpha=0.01, l1_ratio=0.5, max_iter=1000)\n",
    "    \n",
    "    detector = ARIMAXAnomalyDetector(\n",
    "        ar_order=1,\n",
    "        ma_order=1,\n",
    "        # Penalizing the AR/MA terms is often neccesary to get covariates to matter at all\n",
    "        ma_penalty=0.2,\n",
    "        ar_penalty=0.2,\n",
    "        diff_order=0,\n",
    "        seasonal_ar=0,\n",
    "        seasonal_ma=1,\n",
    "        seasonal_period=seasonal_period,\n",
    "        anomaly_threshold=3.0,\n",
    "        regression_model=regression,\n",
    "        #time_features=[],\n",
    "        time_features=['hour'],\n",
    "    )\n",
    "\n",
    "    return detector\n",
    "\n",
    "def add_scores(df, out):\n",
    "    with_scores = pandas.merge(df, out, left_index=True, right_index=True)\n",
    "    with_scores['difference'] = with_scores['input'] - with_scores['prediction']\n",
    "    with_scores['difference_abs'] = with_scores['difference'].abs()\n",
    "    with_scores.index.name = 'Time'\n",
    "    \n",
    "    from scorer import GammaAnomalyTransformer, HalfNormAnomalyTransformer\n",
    "    transformer = HalfNormAnomalyTransformer(severity_factor=0.2)\n",
    "    \n",
    "    #transformer = GammaAnomalyTransformer(use_log=False, severity_factor=1.3)\n",
    "    transformer.fit(1.0*with_scores.difference.abs())\n",
    "    scores = transformer.transform(with_scores.difference.abs())\n",
    "    with_scores['anomaly_score'] = scores\n",
    "    with_scores.head()\n",
    "    return with_scores\n",
    "\n",
    "def make_plotting_config(target, covariates, other=[]):\n",
    "\n",
    "    possible = covariates + other\n",
    "    temperatures = [ c for c in possible if 'Temperature' in c ]\n",
    "    controls = [ c for c in possible if 'Control' in c or 'Occupied' in c ]\n",
    "\n",
    "    groups = {\n",
    "        'Target': [ target ] + ['input', 'prediction'],\n",
    "        'Difference': ['difference', 'difference_abs'],\n",
    "        'Anomaly': ['anomaly_score', 'Fault'],\n",
    "    }\n",
    "    if controls:\n",
    "        groups['Control'] = controls\n",
    "    if temperatures:\n",
    "        groups['Temperatures'] =  temperatures\n",
    "    return groups\n",
    "\n",
    "\n",
    "\n",
    "def anomaly_detect_config(df, config):\n",
    "\n",
    "    plot_groups = make_plotting_config(one['target'], one['covariates'], config.get('related', []))\n",
    "    out, coefficients = anomaly_detection(df, make_detector=make_detector, target=config['target'], covariates=config['covariates'])\n",
    "    scores = add_scores(df, out)\n",
    "\n",
    "    # Create the plot\n",
    "    fig = plot_grouped_timeseries(\n",
    "        df=scores.reset_index(),\n",
    "        date_col='Time',\n",
    "        groups=plot_groups,\n",
    "        title=config.get('name', ''),\n",
    "        height=800\n",
    "    )\n",
    "    \n",
    "    return fig, scores, coefficients\n",
    "\n",
    "one=dict(\n",
    "    target = 'Supply Air Temperature',\n",
    "    covariates = [\n",
    "        #'Occupied',\n",
    "        #'Outdoor Air Temperature',\n",
    "        'Supply Air Temperature Heating Set Point',\n",
    "    ],\n",
    "    related = [],\n",
    ")\n",
    "fig, scores, coefficients = anomaly_detect_config(df, one)\n",
    "fig.show()\n",
    "coefficients.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec2d0a5-1a92-47e8-a504-c64598c18a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "one=dict(\n",
    "    target = 'Heating Coil Valve Control',\n",
    "    covariates = [\n",
    "        'Occupied',\n",
    "        'Outdoor Air Temperature',\n",
    "        'Supply Air Temperature Heating Set Point',\n",
    "    ],\n",
    "    related = [],\n",
    ")\n",
    "fig, scores, coefficients = anomaly_detect_config(df, one)\n",
    "fig.show()\n",
    "coefficients.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20711d2-5a22-41f3-bf81-67d58f8c7647",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3731c7-3c17-47bc-904f-b28d11b25c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "coefficients_groups = {\n",
    "    'One': list(coefficients.columns),\n",
    "}\n",
    "\n",
    "# Create the plot\n",
    "fig = plot_grouped_timeseries(\n",
    "    df=coefficients.reset_index(),\n",
    "    date_col='time',\n",
    "    groups=coefficients_groups,\n",
    "    title='cc',\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6788e780-a8be-4cc9-a97e-48fdeb8e04a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "device-train",
   "language": "python",
   "name": "device-train"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
