{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f19afc9fd7458c45670e586cba4e08b4d828bf89"
   },
   "source": [
    "Data can be found here:\n",
    "\n",
    "https://www.kaggle.com/uciml/human-activity-recognition-with-smartphones/downloads/human-activity-recognition-with-smartphones.zip  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "665af8f0bdd3a44a5833b640ef5491833ce26463"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6675b96bbda6daa79de310f98dc34261199b8131"
   },
   "source": [
    "## 2 - Load and analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "1da6c8b2944249a5feeea241344734229b4380cd"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./har_data/train.csv\")\n",
    "test = pd.read_csv(\"./har_data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "dc785d9325f03d9ae75c87b9bf74a4529a94f045"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "      <th>Activity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "      <td>STANDING</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 563 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-kurtosis()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.710304   \n",
       "1         -0.957686         -0.943068  ...                        -0.861499   \n",
       "2         -0.977469         -0.938692  ...                        -0.760104   \n",
       "3         -0.989302         -0.938692  ...                        -0.482845   \n",
       "4         -0.990441         -0.942469  ...                        -0.699205   \n",
       "\n",
       "   angle(tBodyAccMean,gravity)  angle(tBodyAccJerkMean),gravityMean)  \\\n",
       "0                    -0.112754                              0.030400   \n",
       "1                     0.053477                             -0.007435   \n",
       "2                    -0.118559                              0.177899   \n",
       "3                    -0.036788                             -0.012892   \n",
       "4                     0.123320                              0.122542   \n",
       "\n",
       "   angle(tBodyGyroMean,gravityMean)  angle(tBodyGyroJerkMean,gravityMean)  \\\n",
       "0                         -0.464761                             -0.018446   \n",
       "1                         -0.732626                              0.703511   \n",
       "2                          0.100699                              0.808529   \n",
       "3                          0.640011                             -0.485366   \n",
       "4                          0.693578                             -0.615971   \n",
       "\n",
       "   angle(X,gravityMean)  angle(Y,gravityMean)  angle(Z,gravityMean)  subject  \\\n",
       "0             -0.841247              0.179941             -0.058627        1   \n",
       "1             -0.844788              0.180289             -0.054317        1   \n",
       "2             -0.848933              0.180637             -0.049118        1   \n",
       "3             -0.848649              0.181935             -0.047663        1   \n",
       "4             -0.847865              0.185151             -0.043892        1   \n",
       "\n",
       "   Activity  \n",
       "0  STANDING  \n",
       "1  STANDING  \n",
       "2  STANDING  \n",
       "3  STANDING  \n",
       "4  STANDING  \n",
       "\n",
       "[5 rows x 563 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bdebd2a8a479a9312f208b749f0bd238e68c2819"
   },
   "source": [
    "## FIXME: group folds on subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "aa4c38088ec780b77bd705de0c8c99093e1f7ac4"
   },
   "outputs": [],
   "source": [
    "train.drop('subject', axis =1, inplace=True)\n",
    "test.drop('subject', axis =1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "f0449a47956e256507bfd1cdaa3fc6d7339812c9"
   },
   "outputs": [],
   "source": [
    "for x in [train, test]:\n",
    "    x['Activity'] = x.Activity.astype(\"category\")\n",
    "\n",
    "feature_cols = list(set(train.columns) - set(['Activity', 'subject']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73b43d31220091e9ae65f298f1c99acaec475ae7"
   },
   "source": [
    "## 4 - Splitting the data into train and validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "d0ad37996bbd59446db40248abbb5876d6d6fe9b"
   },
   "outputs": [],
   "source": [
    "#Getting the split indexes\n",
    "\n",
    "split_data = StratifiedShuffleSplit(n_splits = 1, test_size = 0.3, random_state = 42)\n",
    "train_idx, val_idx = next(split_data.split(train[feature_cols], train.Activity))\n",
    "\n",
    "#creating the dataframes\n",
    "\n",
    "x_train = train.loc[train_idx, feature_cols]\n",
    "y_train = train.loc[train_idx, 'Activity']\n",
    "\n",
    "x_val = train.loc[val_idx, feature_cols]\n",
    "y_val = train.loc[val_idx, 'Activity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "caceb4ec079b587086a31daa4bdf3c3fbe32d17a"
   },
   "source": [
    "## 5 - Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2206, 58)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove useless features\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "v = VarianceThreshold(threshold=0.2)\n",
    "v.set_output(transform=\"pandas\")\n",
    "x_train = v.fit_transform(x_train)\n",
    "x_val = v.transform(x_val)\n",
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "18519b63921793021c3d3b1f51dc2adae8caf363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.95048544, 0.94266278, 0.94266278, 0.95238095, 0.94655005])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establish max perf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "rf = RandomForestClassifier(n_estimators = 100)\n",
    "cross_val_score(rf, x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 20/20 [40:25<00:00, 121.27s/it]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scores_to_error(scores):\n",
    "    err = (1.0 - scores)*100\n",
    "    return err\n",
    "\n",
    "def check_sparse_logreg(x_train, y_train, C=1.0, weight_minimum=0.5, cv=5):\n",
    "\n",
    "    # Define model\n",
    "    est = LogisticRegression(C=C, penalty='l1', solver='liblinear', max_iter=10000)\n",
    "    pipe = make_pipeline(StandardScaler(), est)\n",
    "    \n",
    "    # Estimate perf with all features\n",
    "    scores_full = scores_to_error(cross_val_score(pipe, x_train, y_train, cv=cv))\n",
    "\n",
    "    # Figure out which features to select/remove\n",
    "    # FIXME: use SelectFromModel?\n",
    "    pipe.fit(x_train, y_train)\n",
    "    \n",
    "    c = pipe.named_steps['logisticregression'].coef_\n",
    "    weights_selected = np.count_nonzero(c)/np.prod(c.shape)\n",
    "    \n",
    "    feature_weights = np.sum(np.abs(c), axis=0)\n",
    "    features_removed = feature_weights <= weight_minimum\n",
    "\n",
    "    # Estimate perf with subset features\n",
    "    selected_columns = x_train.columns[~features_removed]\n",
    "    x_train_cut = x_train[selected_columns]\n",
    "    scores = scores_to_error(cross_val_score(pipe, x_train_cut, y_train, cv=cv))\n",
    "\n",
    "    results = pandas.Series({\n",
    "        'features_selected': len(selected_columns),\n",
    "        'cv_scores_full': scores_full,\n",
    "        'cv_scores_reduced': scores,\n",
    "        'C': C,\n",
    "        'weight_minimum': weight_minimum,\n",
    "    })\n",
    "    return results\n",
    "\n",
    "complexities = np.logspace(-3, +3, 20)\n",
    "out = []\n",
    "for C in tqdm(complexities):\n",
    "    r  = check_sparse_logreg(x_train, y_train, C=C)\n",
    "    out.append(r)\n",
    "results = pandas.DataFrame(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('logreg-l1-feature-selection-2.csv')\n",
    "del results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pandas.read_csv('logreg-l1-feature-selection-2.csv')\n",
    "\n",
    "def load_csv_embedded_array(s):\n",
    "    def load_one(vv):\n",
    "        l = [ float(p.strip()) for p in vv.strip('[]').split(' ') if p.strip() ]\n",
    "        return l\n",
    "    return s.apply(load_one)\n",
    "    \n",
    "for c in ['cv_scores_full', 'cv_scores_reduced']:\n",
    "    results[c] = load_csv_embedded_array(results[c])\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0 * np.array(data)\n",
    "    n = len(a)\n",
    "    m, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * scipy.stats.t.ppf((1 + confidence) / 2., n-1)\n",
    "    return m, m-h, m+h\n",
    "\n",
    "#def mean_confidence_err(data, **kwargs):\n",
    "#    mean, lower, upper = mean_confidence_interval(data, **kwargs)\n",
    "#    return \n",
    "\n",
    "results['scores_full_mean'] = results['cv_scores_full'].apply(np.mean)\n",
    "#results['scores_full_ci'] = results['cv_scores_full'].apply(mean_confidence_interval)\n",
    "\n",
    "results['scores_reduced_mean'] = results['cv_scores_reduced'].apply(np.mean)\n",
    "#results['scores_reduced_ci'] = results['cv_scores_reduced'].apply(mean_confidence_interval)\n",
    "\n",
    "results = results.drop(columns=['cv_scores_full', 'cv_scores_reduced'])\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import plotly\n",
    "import plotly.express\n",
    "\n",
    "# FIXME: plot both full and reduced, in separate colors\n",
    "# FIXME: add error bars\n",
    "# TODO: include other data on hover, like complexity value\n",
    "fig = plotly.express.scatter(results,\n",
    "                 x=\"features_selected\",\n",
    "                 y=\"scores_reduced_mean\",\n",
    "                 #color=\"species\",\n",
    "                 #error_y=\"scores_reduced_mean\",\n",
    ")\n",
    "fig.update_layout(height=500, width=800,)\n",
    "fig.add_hline(y=2.0, line_width=2, line_dash=\"dash\", line_color=\"green\")\n",
    "fig.update_yaxes(range=[0.0, 10.0])\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
